{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a20733d2e16c949a1469d40e1adfe43a0a74d020c35bd1193ba7baa471c903e3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               tweets  label\n",
       "0   rt @napqilla: no 1, 3 ambisinya menguasai raky...      1\n",
       "1   rt @pandji: nah gue pikir sentimen petahana ok...      1\n",
       "2   rt @pandji: urutan pertama best moment #debat2...      1\n",
       "3   rt @pandji: ini artikel yg menjelaskan ternyat...      1\n",
       "4   rt @mrtampi: agus makin santai.\\nahok makin sa...      0\n",
       "..                                                ...    ...\n",
       "76  rt @pandji: nah gue pikir sentimen petahana ok...      0\n",
       "77  rt @josua_tm: ibu sylvi adalah contoh bahwa wa...      1\n",
       "78  besok saya ajak kesana saja, saya udah survei ...      1\n",
       "79  benerr bgt.. dan tidak mengajak penonton ikut ...      1\n",
       "80  rt @gandy_koz: pak anis,kl pas libur lebaran i...      1\n",
       "\n",
       "[81 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>rt @napqilla: no 1, 3 ambisinya menguasai raky...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>rt @pandji: nah gue pikir sentimen petahana ok...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>rt @pandji: urutan pertama best moment #debat2...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>rt @pandji: ini artikel yg menjelaskan ternyat...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>rt @mrtampi: agus makin santai.\\nahok makin sa...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>rt @pandji: nah gue pikir sentimen petahana ok...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>rt @josua_tm: ibu sylvi adalah contoh bahwa wa...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>besok saya ajak kesana saja, saya udah survei ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>benerr bgt.. dan tidak mengajak penonton ikut ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>rt @gandy_koz: pak anis,kl pas libur lebaran i...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>81 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "name = 'dataset_tweet_2.csv'\n",
    "data = open(name)\n",
    "tokens = csv.reader(data, delimiter=';')\n",
    "tweets = []; label = []\n",
    "for row in tokens:\n",
    "    tweets.append(row[0])\n",
    "    label.append(int(row[1].replace(',','')))\n",
    "df = pd.DataFrame(columns=['tweets','label'])\n",
    "df['tweets'] = tweets\n",
    "df['label'] = label\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              tweets  label  \\\n",
       "0  rt @napqilla: no 1, 3 ambisinya menguasai raky...      1   \n",
       "1  rt @pandji: nah gue pikir sentimen petahana ok...      1   \n",
       "2  rt @pandji: urutan pertama best moment #debat2...      1   \n",
       "3  rt @pandji: ini artikel yg menjelaskan ternyat...      1   \n",
       "4  rt @mrtampi: agus makin santai.\\nahok makin sa...      0   \n",
       "\n",
       "                                             cleaned  \n",
       "0  rt no ambisi kuasa rakyat ambisi layan rakyat ...  \n",
       "1  rt nah gue pikir sentimen tahana oke di malam ...  \n",
       "2  rt urut pertama best moment pak basuki misahin...  \n",
       "3  rt ini artikel yg jelas nyata di yg dapet resp...  \n",
       "4  rt agus makin santainahok makin santunnanies m...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>label</th>\n      <th>cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>rt @napqilla: no 1, 3 ambisinya menguasai raky...</td>\n      <td>1</td>\n      <td>rt no ambisi kuasa rakyat ambisi layan rakyat ...</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>rt @pandji: nah gue pikir sentimen petahana ok...</td>\n      <td>1</td>\n      <td>rt nah gue pikir sentimen tahana oke di malam ...</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>rt @pandji: urutan pertama best moment #debat2...</td>\n      <td>1</td>\n      <td>rt urut pertama best moment pak basuki misahin...</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>rt @pandji: ini artikel yg menjelaskan ternyat...</td>\n      <td>1</td>\n      <td>rt ini artikel yg jelas nyata di yg dapet resp...</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>rt @mrtampi: agus makin santai.\\nahok makin sa...</td>\n      <td>0</td>\n      <td>rt agus makin santainahok makin santunnanies m...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import re, string\n",
    "\n",
    "clean_tweets=  []\n",
    "for tweet in tweets:\n",
    "    def hapus_tanda(tweet): \n",
    "        tanda_baca = set(string.punctuation)\n",
    "        tweet = ''.join(ch for ch in tweet if ch not in tanda_baca)\n",
    "        return tweet\n",
    "    \n",
    "    tweet=tweet.lower()\n",
    "    tweet = re.sub(r'\\\\u\\w\\w\\w\\w', '', tweet)\n",
    "    tweet=re.sub(r'http\\S+','',tweet)\n",
    "    #hapus @username\n",
    "    tweet=re.sub('@[^\\s]+','',tweet)\n",
    "    #hapus #tagger \n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    #hapus tanda baca\n",
    "    tweet=hapus_tanda(tweet)\n",
    "    #hapus angka dan angka yang berada dalam string \n",
    "    tweet=re.sub(r'\\w*\\d\\w*', '',tweet).strip()\n",
    "    \n",
    "    #stemming\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    tweet = stemmer.stem(tweet)\n",
    "    clean_tweets.append(tweet)\n",
    "df['cleaned'] = clean_tweets\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (0, 10)\t0.18913840804590096\n  (0, 233)\t0.27777504205235853\n  (0, 263)\t0.27777504205235853\n  (0, 231)\t0.23692725517145605\n  (0, 170)\t0.20394859337799942\n  (0, 223)\t0.27777504205235853\n  (0, 339)\t0.40789718675599884\n  (0, 215)\t0.27777504205235853\n  (0, 15)\t0.5555500841047171\n  (0, 285)\t0.27777504205235853\n  (0, 346)\t0.0754070869995221\n  (1, 138)\t0.28117693158765905\n  (1, 45)\t0.2624008048150012\n  (1, 241)\t0.2624008048150012\n  (1, 328)\t0.28117693158765905\n  (1, 264)\t0.28117693158765905\n  (1, 403)\t0.24783690942774547\n  (1, 242)\t0.28117693158765905\n  (1, 110)\t0.19637671509980026\n  (1, 291)\t0.28117693158765905\n  (1, 397)\t0.28117693158765905\n  (1, 372)\t0.28117693158765905\n  (1, 320)\t0.24783690942774547\n  (1, 143)\t0.24783690942774547\n  (1, 274)\t0.28117693158765905\n  :\t:\n  (78, 351)\t0.2026045906492247\n  (78, 170)\t0.19396503798408615\n  (79, 256)\t0.3893355655335795\n  (79, 159)\t0.3893355655335795\n  (79, 422)\t0.3893355655335795\n  (79, 68)\t0.3893355655335795\n  (79, 61)\t0.3893355655335795\n  (79, 11)\t0.3558446196149777\n  (79, 95)\t0.2651005234904852\n  (79, 418)\t0.21256859172836773\n  (80, 198)\t0.2650525243728995\n  (80, 168)\t0.2650525243728995\n  (80, 304)\t0.2650525243728995\n  (80, 18)\t0.2650525243728995\n  (80, 104)\t0.2650525243728995\n  (80, 225)\t0.2650525243728995\n  (80, 230)\t0.2650525243728995\n  (80, 307)\t0.2650525243728995\n  (80, 26)\t0.2650525243728995\n  (80, 81)\t0.21352787001187137\n  (80, 196)\t0.22607562800440345\n  (80, 369)\t0.21352787001187137\n  (80, 299)\t0.42705574002374275\n  (80, 339)\t0.19460743887476903\n  (80, 346)\t0.07195332819376485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=2500)\n",
    "model_g = GaussianNB()\n",
    "\n",
    "v_data= vectorizer.fit_transform(df['cleaned'])\n",
    "print(v_data)\n",
    "v_data= vectorizer.fit_transform(df['cleaned']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(v_data, df['label'], test_size=0.2, random_state=0)\n",
    "model_g.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[8 4]\n [1 4]]\n              precision    recall  f1-score   support\n\n           0       0.89      0.67      0.76        12\n           1       0.50      0.80      0.62         5\n\n    accuracy                           0.71        17\n   macro avg       0.69      0.73      0.69        17\nweighted avg       0.77      0.71      0.72        17\n\nnilai akurasinya adalah  0.7058823529411765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "y_preds = model_g.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_preds))\n",
    "print(classification_report(y_test,y_preds))\n",
    "print('nilai akurasinya adalah ',accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "positif\n"
     ]
    }
   ],
   "source": [
    "tweet=''\n",
    "v_data= vectorizer.transform([tweet]).toarray()\n",
    "y_preds = model_g.predict(v_data)\n",
    "if y_preds ==1:\n",
    "    print('positif')\n",
    "else:\n",
    "    print('negatif')"
   ]
  }
 ]
}